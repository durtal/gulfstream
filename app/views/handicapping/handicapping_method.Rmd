---
output: html_fragment
---

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tomhes)
library(RcappeR)
library(dplyr)
library(magrittr)

mongo <- mongo.create()
cursor <- mongo.find(mongo = mongo, ns = "gulf.races")
count <- mongo.count(mongo = mongo, ns = "gulf.races")
output <- vector(mode = "list", length = count)
i <- 1
while(mongo.cursor.next(cursor)) {
    output[[i]] <- mongo.bson.to.list(mongo.cursor.value(cursor))
    i <- i + 1
}
races <- gulf_races_df(races = output)

races %<>% select(date_race:fintime, fs2_5f, fs2f)
rm(count, mongo, i, output, cursor)
onerace <- unique(races$date_race)[565]
onerace <- filter(races, date_race == onerace)
```

### Introduction

This is a detailed(!) look at how ratings in these pages have been created, I try to acknowledge all the flaws and compromises I've had to take, followed by how these could, potentially, be reduced, leading to improvements.  I'll cover a number of important topics in varying degrees of detail, from handicapping preparation, to building an initial handicap, to finally calculating the ratings.

The ratings were created using an R package I've created, called [RcappeR](https://github.com/durtal/RcappeR) which is available on github, so it should be possible for others to reproduce ratings found in these pages.  There are a number of reasons for making ratings that are reproducible, but chief among them is transparency; I hope that it will encourage others to give feedback, spot errors, issues, bugs, etc, which could lead to improvements.  I also hope it leads to discussions about handicapping, allowing people to learn, including myself (I'm very much still learning), from other peoples knowledge and expertise.

The most accessible sections are **Handicapping Preparation** and **Handicapping a single race**, which should give a clear idea of the handicapping method, future handicapping blogs will clearly exhibit it.  The final two sections are a bit more challenging, and possibly confusing (it could definitely be made clearer), but hopefully interesting for some.

The creation of these ratings owe a number of people who either knowingly, or unknowingly, helped me, but they bear no responsibility for the ratings herein.

During the post I will highlight issues, by a bold number in brackets, eg. (**1**), these will all be elaborated upon at the end of the post under the "Issues and Improvements" heading.

### Handicapping Preparation

First up is handicapping preparation, for each race, data is cleaned and checked, making sure a number of variables that are required for the performance of its runners to be assessed are present, these include:

* race surface (dirt or turf)
* race distance
* final times
* weight carried

I use the surface and distance variables to calculate a lbs per second scale(**1**).  Final times are used to calculate the margins, in seconds, between the winner and the rest, before multiplying the beaten seconds by the lbs per second scale, resulting in beaten margins, in lbs.  The difference in the weight the horses carried is added to the beaten lbs, to calculate a final difference at the weights (**2**).  An example of this preparation can be seen below, first the un-prepared race data, followed by the prepared data, including 3 new variables, _btn\_sec_, _btn\_lbs_ and _at\_wgts_.

```{r echo=FALSE}
onerace <- select(onerace, date:race, dist:surf, wgt, pos, fintime)
onerace

(preppedrace <- onerace %>% mutate(btn_sec = btn_sec(fintime),
                   btn_lbs = lbs_per_sec(dist = dist, surf = surf[1]) * btn_sec,
                   at_wgts = diff_at_wgts(btn_lbs = btn_lbs, wgt_carried = wgt)))
```

The above preparation is performed for each and every race that requires handicapping.  There are a couple of vignettes walking through preparation included in the [RcappeR](https://github.com/durtal/RcappeR) package, and are also available in the [help pages](https://durtal.github.io/RcappeR).

### Handicapping a single race

This section explains the method of race standardisation used to handicap a single race.  When handicapping a race via race standardisation, the performance of runners in different yet similar, ie. class and/or type (eg. $12k Claiming, Grade 2 Stakes), are used to assess the level of performance.  The specific method of Race Standardisation I use is one outlined by Simon Rowlands of Timeform ([article here](https://betting.betfair.com/horse-racing/bloggers/simon-rowlands/simon-rowlands-on-handicapping-060710.html)), which uses Zipf's Law.

An example will follow, where a race, **race1**, will be handicapped using a second race, **race2**, that has already been handicapped, ie. the runners have ratings.

```{r echo=FALSE, warning=FALSE, message=FALSE}
data(example_race)
example_race %<>% group_by(date) %>%
    mutate(fintime = conv_margins(btn_l = btn_l, win_time = conv_times(times = wintime)),
           btn_sec = btn_sec(times = fintime),
           scale = lbs_per_sec(dist = dist, surf = "turf"),
           DatW = scale * btn_sec) %>%
    select(date, pos, horse, dist, fintime, DatW)
class(example_race) <- "data.frame"
race1 <- filter(example_race, date == "01/01/01")

race2 <- filter(example_race, date != "01/01/01")
names(race2)[6] <- "rtg"
race2$rtg <- 70 - race2$rtg
```

In short, the difference at the weights (abbreviated to DatW from now) of runners in **race1**, are added to the ratings (which reflect the DatW of its runners, but on a different scale as runners have been awarded a rating), according to finishing position.  So the DatW of the runner-up in **race1** is added to the rating of the runner-up in **race2**, this is done for each finishing position.  The result is a vector of potential ratings for the winner of **race1**.  

Where Zipf's Law comes in is the weighting of these ratings, in Simon's words they are "weighted inversely according to rank: 1/1, 1/2, 1/3 and so on".  So each rating is multiplied by its corresponding Zipf factor, runner up rating is multiplied by 1/2, 3rd placed horse multiplied by 1/3, the ratings are then summed together and divided by the sum of the Zipf factors.  An example:

**race2** has been handicapped, its winner was awarded a rating of `r subset(race2, pos == 1)$rtg`:
```{r echo=FALSE}
race2
```

Meanwhile **race1** hasn't been handicapped, instead we have a dataset that has DatW prepared
```{r echo=FALSE}
race1
```

So the `DatW` variable from **race1** is added to the `rtg` variable in **race2**, as race1 has 3 more runners, these runners are ignored (**3**).  This results in a vector of potential ratings for the winner of **race1**.

```{r echo=FALSE}
(rtgs <- race1$DatW[1:5] + race2$rtg)
zipf_factor <- 1/race2$pos
```

These are then weighted by their corresponding Zipf factors, which are in this example: **`r zipf_factor`**

```{r echo=FALSE}
(rtgs <- rtgs * zipf_factor)
```

These are summed together (`r sum(rtgs)`), before being divided by the sum of the Zipf factors (`r sum(zipf_factor)`), resulting in a rating for the winner of **race1**, based on the performance of runners in its race compared to the performance of runners in a different, but similar race.

```{r echo=FALSE}
(rtg <- sum(rtgs) / sum(zipf_factor))
```

The winner of **race2** is roughly `r subset(race2, pos == 1)$rtg - rtg` lbs better than the winner of **race1**, hopefully that makes it a little clearer.  When using many, different but similar, races to handicap **race1**, a distribution of ratings is produced, from which a single rating for the winner of **race1** can be reached.

There is a vignette included in the [RcappeR](https://github.com/durtal/RcappeR) package that walks through this example, it can also be found in the help pages, [here](https://durtal.github.io/RcappeR/handicap_with_zipf_race.html).

### Initialising a Handicap

This section looks at initialising a handicap using the method of Race Standardisation explained above.  The (significant) difference is that **no** horse has a prior rating, it is a handicap from scratch.  So where the DatW values from **race1** were added to the ratings of **race2** above, instead, DatW values from one race are added (by finishing position) to the DatW values of another race.  The result is the difference between the two races; the difference above was `r subset(race2, pos == 1)$rtg - rtg`.

As mentioned, when using many races to handicap a race a distribution of ratings builds up, from which a rating can be derived.  The possible ratings for a single winner of a race could be normally distributed, or they could be skewed left or right.  However further inspection and analysis of the distribution is infeasible during the initialisation of a handicap, when the number of races should be quite large, so the average rating of this distribution is returned, a compromise I can accept.

There are `r length(unique(races$date_race))` unique races in my database that require handicapping, these are races made up of different types and classes.  The difficulty ahead of initialising the handicap is how to split and group the races.  A lot is common sense, and should be apparent simply by the name of the race, even to the lay fan, ie. a Maiden Claiming is different from a Stakes race.  The counts for each of the different race types is shown below:

```{r echo=FALSE}
counts <- races %>%
    filter(pos == 1) %>%
    group_by(race_type) %>%
    summarise(n = n()) %>%
    arrange(desc(n))
class(counts) <- "data.frame"
counts
```

Within each of these race groups there are differences in the class of horse that compete, meaning races could, nay, should be split further.  However, how they are to be split is unclear, for example, Claiming races could be split according to the value (or purse) of the race, by extra conditions restricting runners able to enter (NW1 L, NW3 X), or by the Claiming price of horses competing.  Some of the conditions for races can be baffling to the most fervent race fan, with course clerks cooking up all sorts of combinations. (**4**)

I ended up taking a lead from Beyer pars for Gulfstream Park, these were found in a DRF PDF preview for the 2012-13 Gulfstream Park season, and while some of the abbreviations aren't immediately recognisable, common sense has been applied.  For example, Maiden Claiming races, were grouped according to the claiming price set for runners in the race, while Allowance Optional Claiming races were grouped by the restrictions placed on runners.  Some of the races in my database aren't covered in the Beyer pars, races such as Starter Optional Claimers ("st op clm" in the above table), or Starter Allowance ("st all" above) races.  I will work through an example using Maiden Claiming.

```{r echo=FALSE, message=FALSE, warning=FALSE}
mdnclm <- filter(races, race_type == "mdn clm")

mdnclmcat <- c(0, 14900, 20000, 34000, 49000, Inf)
mdnclm$cor <- cut(mdnclm$clm_price, breaks = mdnclmcat)

mdnclmwnrs <- filter(mdnclm, pos == 1)
```

There are `r length(unique(mdnclm$date_race))` unique Maiden Claiming races, that require further grouping/subsetting; this is done using the Claiming Price for a race's runners.  The ungrouped claiming prices for Maiden Claiming races is presented first, followed by the 5 groups that will be used:

```{r echo=FALSE, warning=FALSE, message=FALSE}
table(mdnclmwnrs$clm_price)
table(mdnclmwnrs$cor)
```

With these groups created, each race is handicapped using the **_N_** races in the same group.  The result is a handicap, per group.  Below is a plot showing the distribution of ratings for the winners of races in each group.

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', out.height="450px", out.width="600px"}
mdnclm %<>% group_by(date_race) %>%
    mutate(btn_sec = btn_sec(fintime),
           scale = lbs_per_sec(dist = dist, surf = surf[1]),
           btn_lbs = scale * btn_sec,
           diff_wgts = diff_at_wgts(btn_lbs = btn_lbs, wgt_carried = wgt))

hcp <- zipf_init(races = mdnclm, group_by = "cor", race_id = "date_race", btn_var = "diff_wgts")
plot(hcp)
```

The mean of each distribution per group will always be 0, but typically the distribution will be right-skewed, this is due to ratings being a function of margins beaten, in turn a function of race times, which are similarly right skewed.

The ratings in the right-most tail are worthy of scrutiny and could be due to over-exaggerated margins back to well beaten horses in dirt races.  This could be mitigated (and should be in time) by calculating a lbs per second scale for each horse, taking into account the speed it ran its race (see **1**).  Alternatively, any horse whose beaten by some threshold could be ignored, but for the time being no horses are discarded like this.  With these races being Maiden Claiming races I am not too surprised by the longer right tails, as runners in these races will exhibit more variability in readyness, fitness, maturity, and ability.

Something else that is likely to be affecting the ratings in the right most tail, is that the initialisation treats each race in a group as equal, ie. the average ability of runners in each race is the same and they run under the same conditions.  This is clearly false, but the initialisation of handicap can't account for this, which is why this is only the first, initial, step.

### Ratings

As seen in the plot above, despite there being 5 different groups the initial ratings do not distinguish the groups, ie. the ratings are all around 0 and the difference in ability of horses competing in each group is not apparent.  This is possibly the biggest and most challenging of problems:

* What is the difference, in lbs, between an average runner in a Grade 2 Stakes race and an average runner in a Grade 1 Stakes race?

Unlike many other racing jurisdictions (UK & Ire, Hong Kong, etc), the US don't have official ratings for horses, which would help to establish the difference in ability of the runners in each race type/class.  There are things we can potentially learn from the ratings in those jurisdictions, but we'll come to that later.  So a different way to establish the differences is required.

The method to establish the difference in ability of horses in each race type/class is very similar to one laid out by Bob Wilkins in his excellent book [Bioenergetics and Racehorse Ratings](http://www.amazon.co.uk/Bioenergetics-Racehorse-Ratings-Bob-Wilkins/dp/0956424309), chapter 4.3 to be precise.  I don't believe this is the only method  (**5**) and it has some issues, but it is relatively simple - thanks to [Hadleyverse](https://www.github.com/hadley) (Hadley Wickham).

The method is as follows, with some pseudo-code:

1. Calculate the average rating of individual horses
    * `avg_rtg <- mean(rating, na.rm = TRUE)`
2. Calculate the average rating of the ratings in individual races
    * `race_avg <- mean(rating, na.rm = TRUE)`
3. Calculate the average `avg_rtg` of runners in individual races
    * `rnr_avg <- mean(avg_rtg)`
4. Calculate the difference between `race_avg` and `rnr_avg`
    * `diff <- rnr_avg - race_avg`
5. Add `diff` to the `rating`'s of runners in that race
    * `rating <- rating + diff`

Steps 1 thru 5 are repeated, the `diff` variable gets smaller and smaller, and at a certain threshold the iterations can be stopped.  From the above it perhaps isn't quite clear what the code is doing so it is perhaps best to think of an example using a single horse.

So imagine a horse, call him **Mr Zipf**, that typically finishes in the first three, therefore always has a relatively high rating (calculated in the initialisation step above), these high ratings mean a higher average rating (`avg_rtg` in step 1) for **Mr Zipf**.  He competes in a race and comes 2nd, his rating for this race is added to the other runners ratings for this race, to calculate the `race_avg` (step 2).  The higher average rating of **Mr Zipf** then contributes the average rating of runners, `rnr_avg`, in this race (step 3).  This potentially leads to a positive difference, `diff` (step 4), between `rnr_avg` and `race_avg`, which is then added to **Mr Zipf** and the other runners in this race (step 5).  **Mr Zipf**'s increased rating for this race then increases his `avg_rtg` in the next iteration.  And so on...

Returning to the population of horses, the races whose runners have similar race histories to **Mr Zipf** above, ie. consistently in the first three with high ratings, will see these `race_avg`'s increase.  While races whose runners rarely win, and rarely perform, will drag the `race_avg` down.  An example is Maiden races, you won't ever see a winner of a Maiden race back in a maiden race, so the `race_avg` will be more affected by horses who have to repeatedly compete in Maiden races because they can't win.

The process has flaws as I only have races from Gulfstream Park, so horses may have raced just once at Gulfstream Park, which means its entire race history is unknown.  It would be far more effective somewhere like Hong Kong, where there is a consistent pool of ~1200 horses, and I have data on all horses and their performances.  However it achieves something very useful, in that the new ratings for horses can be used to establish the difference between one group and a second, between a Grade 1 Stakes race and a Grade 2 Stakes race.

The output below shows the 20 horses with the highest ratings (`new_rtg`) after the 11 iterations are carried out.  It also shows the number of runs the horse has in the dataset, and the position the horse finished in when recording that rating. What is also displayed is the variable `cor` (category of race) which is the group of race, these groups can be seen below (**6**).

```{r echo=FALSE}
################################################################################
### SPLIT RACES TO CREATE THE GROUPS/SUBSETS

### Maiden Claiming
mdnclm <- filter(races, race_type == "mdn clm")
mdnclm$cor <- cut(mdnclm$clm_price, breaks = c(0, 14900, 20000, 34000, 49000, Inf))
mdnclm$cor <- paste(mdnclm$race_type, mdnclm$cor, sep = " - ")

### Maiden Special Weight
mdnspwgt <- filter(races, race_type == "mdn sp wgt")
mdnspwgt$cor <- cut(mdnspwgt$value, breaks = c(0, 40000, 50000, Inf))
mdnspwgt$cor <- paste(mdnspwgt$race_type, mdnspwgt$cor, sep = " - ")

### Claiming
clm <- filter(races, race_type == "clm")
clm$cor <- cut(clm$clm_price, breaks = c(0, 7500, 10000, 14900, 20000, 34000, 49000, Inf))
clm$cor <- paste(clm$race_type, clm$cor, sep = " - ")

### Starter Optional Claiming
stopclm <- filter(races, race_type == "st op clm")
stopclm$cor <- cut(stopclm$clm_price, breaks = c(0, 10000, 20000, 40000, Inf))
stopclm$cor <- paste(stopclm$race_type, stopclm$cor, sep = " - ")

### Starter Allowance/Handicap
stall <- filter(races, race_type %in% c("st all", "st hcp"))
stall$cor <- "st all / st hcp"

### Allowance Optional Claiming / Allowance
allop <- filter(races, race_type %in% c("all op clm", "all"))
allop$cor <- paste("all op clm / all", stringr::str_extract(string = allop$race_cond, pattern = "nw\\d"), sep = " - ")

### Stakes
stk <- filter(races, race_type == "stk")
stk$cor <- paste(stk$race_type, stk$race_cond, sep = " - ")

################################################################################
### RECOMBINE DATA AND CALL zipf_init

df <- rbind(mdnclm, mdnspwgt, clm, stopclm, stall, allop, stk)
rm(mdnclm, mdnspwgt, clm, stopclm, stall, allop, stk)

### Create difference at the weights variable
df %<>%
    group_by(date_race) %>%
    mutate(btn_sec = btn_sec(fintime),
           scale = lbs_per_sec(dist = dist, surf = surf[1]),
           btn_lbs = scale * btn_sec,
           diff_wgts = diff_at_wgts(btn_lbs = btn_lbs, wgt_carried = wgt))

### Use zipf_init
hcp <- zipf_init(races = df, group_by = "cor", race_id = "date_race", btn_var = "diff_wgts")

### Merge ratings back into dataframe
df <- merge_zipf_init(zipf_list = hcp, races = df, btn_var = "diff_wgts")

df %<>%
    group_by(horse) %>%
    mutate(runs = n(), avg_rtg = mean(zipf_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(zipf_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = zipf_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup() %>%
    group_by(horse) %>%
    mutate(avg_rtg = mean(new_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(new_rtg, na.rm = TRUE),
           diff = mean(avg_rtg, na.rm = TRUE) - race_avg,
           new_rtg = new_rtg + diff) %>%
    ungroup()

top20 <- df %>%
    arrange(desc(new_rtg)) %>%
    select(cor, horse, new_rtg, pos, runs) %>%
    head(20)

top20
```

It is reassuring to see a number of **big** names near the top, especially the likes of Dreaming of Julia, whose two runs both feature in the top20.  What is also pleasing is the number of Stakes races that appear in the `cor` variable, this despite the fact that there aren't as many in the dataset (see above for counts).  What is not so pleasing is the number of Maiden races that appear.  This is largely due to not having a horses entire history of races.  So these ratings can't be entirely trusted, however they are more than useful.

What these new ratings can be used for is to help establish the differences between the groups, using the average rating for performances in each group, the `cor` variable.  The output is shown below, it calculates the average rating (`avg_rtg`) awarded to a runner in that group, the standard deviation (`sd_rtg`) for ratings, and the difference between the biggest `avg_rtg` and each group.  It is this difference that is used.

```{r echo=FALSE}
diff_df <- df %>%
    group_by(cor) %>%
    summarise(rnrs = n(),
              avg_rtg = round(mean(new_rtg, na.rm = TRUE), 2),
              sd_rtg = round(sd(new_rtg, na.rm = TRUE), 2)) %>%
    arrange(desc(avg_rtg)) %>%
    mutate(diff = round(avg_rtg - max(avg_rtg), 2))

diff_df
```

The question earlier:

* What is the difference, in lbs, between an average runner in a Grade 2 Stakes race and an average runner in a Grade 1 Stakes race?

Answer now:

```{r echo=FALSE}
subset(diff_df, cor == "stk - grade 2")$avg_rtg - subset(diff_df, cor == "stk - grade 1")$avg_rtg
```

The list, for the most part, tallies with intuition, Grade 1 is greater than Grade 2 and Grade 3.  Claiming races are ordered from the group of races whose claiming price is $49000 or more ("Clm - (4.9e+04,Inf]"), down to Claiming races whose claiming price is from $0 to $7500 ("Clm - (0,7.5e+03]").  There are a few anomalies, such as Starter Optional Claiming ("St Op Clm") races being out of order, ie "st op clm - (1e+04,2e+04]" has a smaller `diff` than "st op clm - (4e+04,Inf]" and "st op clm - (2e+04,4e+04]", whose runners have higher Claiming prices.

This is where other jurisdictions come in in helping to calculate _final_ ratings.  The average rating of runners in Group 1 (same as Grade 1 in the US) races in Hong Kong is 118.  Timeform (via [wiki](http://en.wikipedia.org/wiki/Timeform) at least) regard an average Group 1 winner as rated between 125 and 129, the average rating of runners in Group 1s is likely to be similar to that in Hong Kong.  

Gulfstream Park is just a subset of US racing, and while it is one of the more promiment racetracks, the average rating of a runner in one of its Grade 1s isn't likely to be as high as those in Hong Kong or the UK.  So I estimated an average rating of 113 for Grade 1 runners.

This estimate is then used to flesh out the handicap.  This difference, `r subset(diff_df, cor == "stk - grade 2")$avg_rtg - subset(diff_df, cor == "stk - grade 1")$avg_rtg` for Grade 2 vs Grade 1 runners, is added to the difference between the average performances for horses in that group and the average performance in each individual race in that group, to get an idea of the strength of an individual race in a group, this difference is then added (it is a negative number) to 113.

The result is a handicap, or the start of a handicap, that will need to be maintained, updated, analysed.  The top 20 performances at Gulfstream Park since December 2012 are as follows:

```{r echo=FALSE}
df %<>%
    group_by(cor) %>%
    mutate(cor_rtg = mean(new_rtg, na.rm = TRUE),
           cor_zipf = mean(zipf_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(date_race) %>%
    mutate(race_avg = mean(zipf_rtg, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(cor_diff = cor_rtg - max(cor_rtg),
             r_diff = race_avg - cor_zipf,
             DIFF = zipf_rtg + r_diff + cor_diff,
             RRtg = 113 + DIFF) %>%
    ungroup()

df %>%
    group_by(horse) %>%
    mutate(runs = n()) %>%
    ungroup() %>%
    arrange(desc(RRtg)) %>%
    select(cor, pos, horse, RRtg, runs) %>%
    head(20)
```

### Issues and Improvements

This section, probably the most important, addresses the issues I **have** spotted and am aware of, others will certainly elude me, which is the precise reason for being as transparent as possible.  So I'll run through them, offering potential solutions where possible.

**1**  -  The lbs per second scale I use is a version of one outlined by Bob Wilkins in [Bioenergetics and Racehorse Ratings](http://www.amazon.co.uk/Bioenergetics-Racehorse-Ratings-Bob-Wilkins/dp/0956424309).  However each runner in a race should get its own lbs per second scale based on the speed at which it ran the race.  The difference between the current lbs per second scale and one that would take into account speed is marginal, it would help reduce the influence on ratings by horses beaten by huge margins, but for the time being I intend to adhere to the KISS principle (Keep It Simple Stupid).

**2**  -  The age of runners in a race is not accounted for yet, this is a long standing debate in racing as to the difference in maturity between horses of different ages at different times of the year.  Admiral Rous first devised a weight for age scale in the 19th Century, since then, as I understand it, it has remained quite consistent.  I believe different organisations, such as Timeform, the Racing Post, and the BHA, use different weight for age scales, some of which are public.  I could use an existing, public, weight for age scale, but with the difference in opinion I want to hold fire for now.  

Races at Gulfstream Park are typically run from December to April, with summer racing only a recent addition, this means that 2yos, at least in my database, haven't ever run against older horses.  While ~33% of races in my database sees 3yo horses take on older horses, which means this issue must be addressed.  Ideas for potential solutions, outside of using an existing scale, would be welcomed.

**3**  -  The shortening of the field and ignoring runners because it differs in field size, sees a loss of information that is a little wasteful.   I don't believe this is a huge issue when using many races to handicap a race, however analysis (regression?) of runners who did finish, and contribute either a rating or a DatW value, could help to extend the number of runners.

**4**  -  The splitting and grouping of races to get similar races in the same group is a challenge as it will have a big impact on ratings.  I also don't want to get so specific that causes very small samples, already evidenced there is only one race classed as "St Hcp".  The shortcut I have taken is to use the experience of other horseplayers in the grouping of races, and a touch of common sense, but there are potential alternatives that I may get round to exploring.

One such solution is to try to get the horses to tell me, ie. the race record of a horse can highlight the class system, a horse wins it likely steps up a class, narrowly loses it might take a small step up or stay in the same or similar class, loses badly they might need to step down.  A single horse can exhibit this in its history, so ~5000 horses could help paint an accurate picture of the class system.

* Which races do winners of a Maiden Claiming with a claiming price of $19k compete in next compared to the winners of Maiden Special Weight with a purse of $43k?
* Where do winners of $50k Claiming races appear next compared to winners of $25k Allowance Optional Claimers?

These questions are simple ones, but when dealing with a large number of runners it has to be solved computationally.  A solution, I think, is matrix related, for example, an empty matrix is the starting point, the columns and rows correspond to different race types, as such:

```{r, echo=FALSE}
(matrix_eg <- matrix(data = NA, nrow = 4, ncol = 4, dimnames = list(c("mdn clm 19k", "mdn sp wgt 43k", "clm 50k", "all op clm 25k"),c("mdn clm 19k", "mdn sp wgt 43k", "clm 50k", "all op clm 25k"))))
```

Let's assume this matrix is for horses who have finished in the first 3, the matrix is then populated as and when a horse moves from one race type/class to another, building counts, for example, 3 horse ran in a "mdn clm 19k" race, one ran in another "mdn clm 19k", the other two competed in "all op clm 25k", etc, etc.

```{r echo=FALSE}
matrix_eg[1,1] <- 1
matrix_eg[1,4] <- 2
matrix_eg[2,1] <- 2
matrix_eg[2,3] <- 1
matrix_eg[3,3] <- 3
matrix_eg[4,3] <- 2
matrix_eg[4,4] <- 1
matrix_eg
```

Thinking about problems like this is quite easy, describing them so a computer understands and can interpret is not so easy.  This problem also holds a key to another issue, what is the difference, in lbs, between a winner of a Maiden Claiming race with a purse of $19k and the winner of a Maiden Special Weight with a purse of $43k?  See also **5**


**5**  -  I take a lead from a section in Bob Wilkins' book ([Bioenergetics and Racehorse Ratings](http://www.amazon.co.uk/Bioenergetics-Racehorse-Ratings-Bob-Wilkins/dp/0956424309), chapter 4.3 to be precise) that spells out a method of using all races and performances to build collateral form lines, using all runners and all races.  As mentioned I only have the performances of a horse that has raced at Gulfstream Park, so I am missing the chance to build collateral form lines.

But I do think it possible to track a horses performance using matrices similar to those outlined in section **4**.  However, even with a small database of `r length(unique(df$horse))` runners and `r length(unique(df$date_race))` races, means a matrix of `r length(unique(df$horse)) * length(unique(df$date_race))` elements, of which only `r length(df$date_race)` are **NOT** NA values.  Bob Wilkins writes of Sparsity Oriented Programming, but this is **way** beyond my ability, so the compromise in the above **Ratings** section was reached.

A simpler (I say simpler, ha!) option may be to measure the performance of each horse across the different races they compete in.  So if a horse earns a rating of 8 in a Maiden Claiming race, and then earns a rating of -25 in a Allowance Optional Claiming race, then the difference of -33 can be used.  Extrapolating that out to account for **ALL** horses, and averaging these differences, may establish the difference between one group of race and another.

Another application I recently read about was written by Martin Eastwood, [Massey Ratings for Football](http://pena.lt/y/2014/11/27/english-premier-league), which is a smaller but similar problem (I think).

Any input would be welcomed.

**6** - The different groups are shown below, with the number of races per group.  To walk through how they were divided:

* **Maiden Claiming** ("Mdn Clm"), **Claiming** ("Clm") and **Starter Optional Claiming** ("St Op Clm") races were split up according to the claiming price set for runners
* **Starter Allowance** ("St All") and **Starter Handicap** ("St Hcp") were simply combined
* **Maiden Special Weight** races were split according to purse/race value
* **Allowance Optional Claiming** and **Allowance** races were combined and then grouped according to the restrictions set for runners
* **Stakes** races were split according to the Graded status

```{r echo=FALSE}
df %>% filter(pos == 1) %>%
    group_by(cor) %>%
    summarise(n_races = n())
```